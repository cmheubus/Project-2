---
title: "Project 2 - ST 558 - CM Heubusch"
output: 
  html_document:
    toc: yes
    depth: 2

---
# Introduction - **NEEDS TO BE COMPLETED**
*You should have an introduction section that describes the data, the purpose of your analysis, and the
methods youâ€™ll use (roughly - more detail can be given later in the document).*

## Purpose of Analysis 

## Methods Used

## Describing the Data & Variables
The [**Online News Popularity** data set](https://archive.ics.uci.edu/ml/datasets/Online+News+Popularity#) describes two years' worth of articles that were published on [Mashable](https://mashable.com/). In total, the data set consists of 39,644 observations, with 61 columns of different variables. In examining the variables, I was particularly intrigued by the following:  
* n_tokens_title - *"number of words in the title"*  
* n_tokens_content - *"number of words in the content"*  
* num_hrefs - *"number of links" in the article*  
* num_imgs - *"number of images"*  
* num_videos - *"number of videos"*  
* average_token_length - *average word length in the article*
* num_keywords - *how many keywords are included in the metadata, an important factor for search engine optimization*
* data_channel_is_* variables - *six binary variables, indicating whether the observation is included in a particular channel. Each article appears to only be attributed to either one channel, or no channel/another channel (perhaps smaller) that was not accounted for with these binary variables*  
* global_rate_positive_words - *"rate of positive words in the content," or rather, the ratio of positive:total words in the article*  
* global_rate_negative_words - *"rate of negative words in the content," the complement to global_rate_positive_words*  

The **weekday_is_** variables will be our means of creating seven separate reports. They are binary variables, so their value is either 0 (for No, not published that day of the week) or 1 (Yes, published that day). **weekday_is_weekend** is 1 if the article was published on *either* Saturday or Sunday. 

# Loading Packages & Reading in the Dataset 
```{r setup, include=FALSE}
library(caret)
library(corrplot)
library(GGally)
library(randomForest)
library(tidyverse)
```

```{r Reading in Dataset}
newsData <- read.csv(file="/Users/christinemarieheubusch/Project-2/OnlineNewsPopularity/OnlineNewsPopularity.csv")
#Removing URL and timedelta columns, since these variables are non-predictive.
newsData <- newsData %>% select(-url, -timedelta)
#str(newsData)
head(newsData)
```

## Creating New Column Using `Mutate`
I was intrigued by the **data_channel_is_** columns in the set, so I decided to figure out a way to combine these columns into a single **channel** column with the `mutate()`function. Working off a [StackOverflow example](https://stackoverflow.com/questions/55126134/nested-ifelse-statement-with-multiple-columns), I used [`dplyr::case_when`](https://www.rdocumentation.org/packages/dplyr/versions/0.7.8/topics/case_when) to assign values based upon the values within the from the six **data_channel_is_** columns. 

I then realized that not every article was associated with a channel; so I used the [`replace_na()` function](https://tidyr.tidyverse.org/reference/replace_na.html) from the `tidyr` package to replace NAs with "Other". (This is an assumption on my end - it's possible that some articles are not assigned to any channel.)

I finished this by converting the values of the **channel** column to factors, removing the URL column (since it will not be used in any calculations), and removed the old **data_channel_is_** columns, for a new total of 55 columns for the dataset. I can now use this column for categorical variables. 
```{r Creating the **channel** Column and Removing **url**}
newsData <- newsData %>% 
            mutate(channel = case_when(
               data_channel_is_bus == 1 ~ "Business",
               data_channel_is_entertainment == 1 ~ "Entertainment",
               data_channel_is_lifestyle == 1 ~ "Lifestyle",
               data_channel_is_socmed == 1 ~ "SocialMedia",
               data_channel_is_tech == 1 ~ "Tech",
               data_channel_is_world == 1 ~ "World"
               ))
newsData$channel <- replace_na(newsData$channel, "Other")
newsData$channel <- as.factor(newsData$channel) #Converting to factor
#newsData <- newsData %>%
#            select(-url, -timedelta, -starts_with("data_channel_is_")) 
            #Removing non-predictive columns of url and timedelta, as well as old **data_channel_is_** columns
view(newsData)
```

## Splitting the Data 
Per the project directions, I then split the data, using `sample()`, with 70% of the data going to the training set (4,662 observations, **newsDataTrain**) and 30% going to the test set (1,999 observations, **newsDataTest**).
```{r Split the Data into Train and Test}
newsData <- newsData %>% filter(weekday_is_monday==1)
#NEED TO FIND A WAY TO AUTOMATE THIS FOR EACH DAY - likely a loop?
#colnames(newsData)
set.seed(789) #Setting seed to make it reproducible
train <- sample(1:nrow(newsData), size=nrow(newsData)*0.7)
test <- dplyr::setdiff(1:nrow(newsData), train)
newsDataTrain <- newsData[train,]
newsDataTest <- newsData[test,]
#view(newsDataTrain)
#view(newsDataTest)
```

Now let's see if any of the variables that intrigued me should be included in my multiple linear regression.

# Summarizations
*You should produce some basic (but meaningful) summary statistics about the training data you are working
with. The GENERAL things that the plots describe should be explained but, since we are going to automate
things, there is no need to try and explain particular trends in the plots you see (unless you want to try and
automate that too!).*

## Calculating Summary Statistics for Variables
I then used the `summary()` function to calculate summary statistics for each of the quantitative variables in the dataset, including Min, 1st Quartile, Median, Mean, 3rd Quartile, and Max. For the one categorical variable I created (**channel**), it has calculated the frequency of each type of channel. I also pulled the 
```{r Calculating Summaries of Each Variable}
summary(newsDataTrain)
```

I further explored the data by looking at a correlations plot with the variables I had expressed interest in previously. I divided the variables into different chunks, to make the plots easier to view. I excluded **weekday_is** variables, as I felt they would only be used for the final creation of the reports, as opposed to being involved in the model. I used the code from our notes *(Module 7 - Summarizing Data/Quantitative Summaries)* for this purpose. 

## Creating First Correlation Plot with First 10 Variables
```{r Creating First Correlation Plot with First 10 Variables}
newsCorrelation1 <- cor(newsData[,c(1:10, 59)])
corrplot(newsCorrelation1, type="upper", method="number", tl.pos="lt", number.cex=0.5)
corrplot(newsCorrelation1, type="lower", add=TRUE, tl.pos="n", number.cex=0.5)
```
## Creating Second Correlation Plot with Other Variables
```{r Creating Second Correlation Plot with Other Variables}
newsCorrelation2 <- cor(newsData[,c(11:20, 59)])

corrplot(newsCorrelation2, type="upper", method="number", tl.pos="lt", number.cex=0.5)
corrplot(newsCorrelation2, type="lower", add=TRUE, tl.pos="n", number.cex=0.5)
```
## Creating Third Correlation Plot
```{r Creating Third Correlation Plot}
newsCorrelation3 <- cor(newsData[,c(21:28, 59)]) #excluding "weekday_is variables"
corrplot(newsCorrelation3, type="upper", method="number", tl.pos="lt", number.cex=0.5)
corrplot(newsCorrelation3, type="lower", add=TRUE, tl.pos="n", number.cex=0.5)
```
## Creating Fourth Correlation Plot
```{r Creating Fourth Correlation Plot}
newsCorrelation4 <- cor(newsData[,c(38:47, 59)]) #excluding "weekday_is" variables
corrplot(newsCorrelation4, type="upper", method="number", tl.pos="lt", number.cex=0.5)
corrplot(newsCorrelation4, type="lower", add=TRUE, tl.pos="n", number.cex=0.5)
```
## Creating Fifth Correlation Plot
```{r Creating Fifth Correlation Plot}
newsCorrelation5 <- cor(newsData[,c(48:58, 59)]) #excluding "weekday_is" variables
corrplot(newsCorrelation5, type="upper", method="number", tl.pos="lt", number.cex=0.5)
corrplot(newsCorrelation5, type="lower", add=TRUE, tl.pos="n", number.cex=0.5)
```

## Creating Extra Correlation Plot
I also created an extra correlation plot, to examine some variables that I had taken an interest in, where I thought there could be relationships between the predictor variables. I thought these would be of interest, as perhaps the number of keywords in the metadata would affect likelihood of someone finding the article through SEO (and then sharing it); or maybe social media users would gravitate towards longer/shorter titles, longer/shorter articles, longer/short words, articles with more negative words, and/or articles that have more links, images, or videos.  
```{r Creating Correlation Plot with Only Some Variables}
newsCorrelation6 <- cor(newsData[,c("num_keywords", "n_tokens_title","n_tokens_content", "num_hrefs", "num_imgs", "num_videos", "average_token_length", "num_keywords", "global_rate_positive_words", "global_rate_negative_words", "shares")])
corrplot(newsCorrelation6, type="upper", method="number", tl.pos="lt", number.cex=0.5)
corrplot(newsCorrelation6, type="lower", add=TRUE, tl.pos="n", number.cex=0.5)
```

Unfortunately,looking at these six plots, I do not see a substantial relationship between any one variable and the target variable of **shares** - those low values all appear faded on the correlation plots, representing weak relationships. However, with my final plot I do note some correlation between other variables, suggesting that there may be interactions between them. For example, the highest correlation coefficient value is r=0.45, when looking at num_hrefs and n_tokens_content. This does seem to make practical sense; the more words you have, the more likely you'll need to include more links. Perhaps less intuitive is the relationship between num_imgs and num_hrefs, with the second-highest correlation coefficient of r=0.36.

I then created a boxplot showing the shares, classified by the categorical variable of channel that I had created. The summary data (which included all channels) indicated that the median number of shares was around 1400 shares per article, though numerous outliers skew this significantly, so that the mean was 3436 shares. Looking at the plots, there do not seem to be dramatic differences in the data based upon which channel an article has been classified under. 
```{r Creating Boxplot of Shares, by Channel}
channelsBoxplot <- ggplot(newsDataTrain, aes(x=channel, y=shares))
channelsBoxplot + geom_boxplot()
```

## Creating `ggpairs` Plots
I also created two sets of ggpairs plots, to look at possible relationships in a different way. I again used the variables I looked at in the sixth correlation plot from above. 
```{r ggpairs1, message=FALSE}
newsData %>% select("num_keywords", "n_tokens_title","n_tokens_content", "num_hrefs", "num_imgs", "shares") %>% ggpairs()
```

```{r ggpairs2, message=FALSE}
newsData %>% select("num_videos", "average_token_length", "num_keywords", "global_rate_positive_words", "global_rate_negative_words", "shares") %>% ggpairs()
```


# Modeling

## Multiple Linear Regression
While all the correlations are still very weak, I'm going to try several different combinations of variables that exhibit the highest correlations to our target variable of shares. 

```{r}

```



Feel free to use code similar to the notes or use the caret package.

## Creating Model with All Main Effects
```{r}
dataFitAll <- lm(shares~., data=newsDataTrain) 
#Includes all main effects, but does not include interactions or quadratics.
summary(dataFitAll)
```

When we look at the results of this multiple linear regression, we see that the Adjusted R-square values is a very low **0.05065**, but we do see that the F-statistic is 6.075, with a very small p-value; it appears that the F-test is significant, in turn suggesting that the model is significant - but we don't know which variables are significant.  To try to determine this, we can examine the resulting p-values of each variable. With an alpha value of 0.01, the following variables are considered significant:
* n_tokens_title  
* num_hrefs  
* num_imgs  
* average_token_length  
* kw_avg_max
* kw_min_avg 
* kw_max_avg  
* kw_avg_avg 
* LDA_00  
* global_subjectivity  
* min_positive_polarity  
* data_channel_is_lifestyle  
* data_channel_is_entertainment  
* data_channel_is_bus           
* data_channel_is_socmed  
* data_channel_is_tech  
* data_channel_is_world  

## Creating Multiple Linear Regression Model with Only the 16 Significant Predictive Variables
In reducing the variables, I'm conducting a **backwards selection** - starting with all variables, and then narrowing them down based upon p-value. However, incorporating only these 16 variables into the model reduces the adjusted R-square to just **0.05102**, a very small improvement. We again have a large F-statistic (16.66) with a small p-value (< 2.2e-16). 
```{r}
dataFit16 <- lm(shares~n_tokens_title +
        num_imgs + 
        average_token_length + 
        kw_avg_max + 
        kw_max_avg + 
        kw_min_avg + 
        kw_avg_avg +
        LDA_00 +
        global_subjectivity + 
        min_positive_polarity + 
        data_channel_is_lifestyle + 
        data_channel_is_entertainment + 
        data_channel_is_bus +          
        data_channel_is_socmed + 
        data_channel_is_tech +
        data_channel_is_world,
      data=newsDataTrain)
summary(dataFit16)
```

This line may be written as:
**Estimated Shares = (n_tokens_title)(1.314e+02) + (num_imgs)(2.473e+01) + (average_token_length)(-3.080e+02) + (kw_avg_max)(-2.175e-01) + (kw_max_avg)(-2.175e-01) + (kw_min_avg)(-6.433e-01) + (kw_avg_avg)(2.055e+00) + (LDA_00)(2.488e+03) + (global_subjectivity)(5.931e+03) + (min_positive_polarity)(-4.452e+03) + (data_channel_is_lifestyle)(-2.650e+03) + (data_channel_is_entertainment)(-2.935e+03) + (data_channel_is_bus)(-3.624e+03) + (data_channel_is_socmed)(-2.718e+03) + (data_channel_is_tech)(-2.321e+03) + (data_channel_is_world)(-1.863e+03)**

## Creating Multiple Linear Regression Model with Only 14 Significant Predictive Variables
Now, I'm going to remove the two variables that are NOT significant from **dataFit16**, and conduct another linear regression. However, even though the result returned indicates that all variables are significant at the alpha=0.05 level, this model reduced the Adjusted R-square to **0.05055**. I will not be further reducing this model and would prefer to use the previous model, with the higher Adjusted R-square value (**dataFit16**).

```{r Testing Model with 14 Variables}
dataFit14 <- lm(shares~n_tokens_title +
        kw_avg_max + 
        kw_max_avg + 
        kw_min_avg + 
        kw_avg_avg +
        LDA_00 +
        global_subjectivity + 
        min_positive_polarity + 
        data_channel_is_lifestyle + 
        data_channel_is_entertainment + 
        data_channel_is_bus +          
        data_channel_is_socmed + 
        data_channel_is_tech +
        data_channel_is_world,
      data=newsDataTrain)
summary(dataFit14)
```

```{r}
residuals <- resid(dataFit16)
plot(residuals)
```

```{r}
#CREATE PREDICTION INTERVAL
```

```{r}
#CREATE INTERVAL 
```

## Creating Model with Random Forest

Per the notes, the random forest method help us obtain a "more corrlated" version of bagged tree predictions, ensuring that a hypothetical really strong predictor doesn't wind up in every bootstrap tree. With this method, we might NOT use all predictors - instead, it'll be "a random subset of predictors for each bootstrap sample/tree fit". 
```{r}
rfNewsDataFit <- randomForest(shares~., data=newsDataTrain, mtry=ncol(newsDataTrain)/3, ntree=200, importance=TRUE)
```

```{r}
trctrl <- trainControl(method="repeatedcv", number=10, repeats=3)
set.seed(1)
rfNewsDataFitCaret <- train(shares ~., data=newsDataTrain, method="knn",
                            trainControl=trctrl,
                            preProcess = c("center", "scale"))
```

```{r}
rfNewsDataFitCaret
```


```{r}
rfNewsDataPred <- predict(rfNewsDataFit, newdata=newsDataTest)
fit16NewPred <- predict(dataFit16, newdata=newsDataTest)
```

## Comparing Two Models with Root MSE

I compared the random forest model to  to our linear model from before, **dataFit16**. To determine which model is preferrable, we can compare the root MSE values. 
```{r Calculating Root MSE values}
rfRMSE <- sqrt(mean((rfNewsDataPred-newsDataTest$shares)^2))
rfRMSE

datafit16RMSE <- sqrt(mean((fit16NewPred-newsDataTest$shares)^2))
datafit16RMSE
```

BOTH models have a very similar RMSE. A lower RSME is preferred; in this case, the linear regression model - **dataFit16** - is considered a better fit than the random forest option.

After training/tuning your two types of models (linear and non-linear) using cross-validation, AIC, or your
preferred method (all on the TRAINING data set only!) you should then compare them on the test set. Your methodology for choosing your model during the training phase should be explained.* 

# Automation
Once youâ€™ve completed the above for Monday, adapt the code so that you can use a parameter in your build process that will cycle through the weekday_is_* variables.
*... adding a loop?* SEE MODULE 8